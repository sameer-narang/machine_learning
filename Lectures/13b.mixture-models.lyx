#LyX 2.2 created this file. For more info see http://www.lyx.org/
\lyxformat 508
\begin_document
\begin_header
\save_transient_properties true
\origin /Users/drosen/Dropbox/repos/mlcourse/Lectures/
\textclass beamer
\begin_preamble
\usetheme{CambridgeUS} 
\beamertemplatenavigationsymbolsempty

\AtBeginSection[]{
  \begin{frame}
  \vfill
  \centering
  \begin{beamercolorbox}[sep=8pt,center,shadow=true,rounded=true]{title}
    \usebeamerfont{title}\insertsectionhead\par%
  \end{beamercolorbox}
  \vfill
  \end{frame}
}
\end_preamble
\options handout
\use_default_options false
\maintain_unincluded_children false
\language english
\language_package default
\inputencoding auto
\fontencoding global
\font_roman "times" "default"
\font_sans "default" "default"
\font_typewriter "default" "default"
\font_math "eulervm" "auto"
\font_default_family default
\use_non_tex_fonts false
\font_sc false
\font_osf false
\font_sf_scale 100 100
\font_tt_scale 100 100
\graphics default
\default_output_format default
\output_sync 0
\bibtex_command default
\index_command default
\paperfontsize default
\spacing single
\use_hyperref false
\papersize default
\use_geometry true
\use_package amsmath 2
\use_package amssymb 2
\use_package cancel 0
\use_package esint 0
\use_package mathdots 0
\use_package mathtools 0
\use_package mhchem 0
\use_package stackrel 0
\use_package stmaryrd 0
\use_package undertilde 0
\cite_engine basic
\cite_engine_type default
\biblio_style plain
\use_bibtopic false
\use_indices false
\paperorientation portrait
\suppress_date false
\justification true
\use_refstyle 0
\index Index
\shortcut idx
\color #008000
\end_index
\secnumdepth 2
\tocdepth 2
\paragraph_separation indent
\paragraph_indentation default
\quotes_language english
\papercolumns 1
\papersides 1
\paperpagestyle default
\tracking_changes false
\output_changes false
\html_math_output 0
\html_css_as_file 0
\html_be_strict false
\end_header

\begin_body

\begin_layout Standard
\begin_inset FormulaMacro
\newcommand{\reals}{\mathbf{R}}
\end_inset

 
\begin_inset FormulaMacro
\newcommand{\integers}{\mathbf{Z}}
\end_inset

 
\begin_inset FormulaMacro
\newcommand{\naturals}{\mathbf{N}}
\end_inset

 
\begin_inset FormulaMacro
\newcommand{\rationals}{\mathbf{Q}}
\end_inset

 
\begin_inset FormulaMacro
\newcommand{\ca}{\mathcal{A}}
\end_inset

 
\begin_inset FormulaMacro
\newcommand{\cb}{\mathcal{B}}
\end_inset

 
\begin_inset FormulaMacro
\newcommand{\cc}{\mathcal{C}}
\end_inset

 
\begin_inset FormulaMacro
\newcommand{\cd}{\mathcal{D}}
\end_inset

 
\begin_inset FormulaMacro
\newcommand{\ce}{\mathcal{E}}
\end_inset

 
\begin_inset FormulaMacro
\newcommand{\cf}{\mathcal{F}}
\end_inset

 
\begin_inset FormulaMacro
\newcommand{\cg}{\mathcal{G}}
\end_inset

 
\begin_inset FormulaMacro
\newcommand{\ch}{\mathcal{H}}
\end_inset

 
\begin_inset FormulaMacro
\newcommand{\ci}{\mathcal{I}}
\end_inset

 
\begin_inset FormulaMacro
\newcommand{\cj}{\mathcal{J}}
\end_inset

 
\begin_inset FormulaMacro
\newcommand{\ck}{\mathcal{K}}
\end_inset

 
\begin_inset FormulaMacro
\newcommand{\cl}{\mathcal{L}}
\end_inset

 
\begin_inset FormulaMacro
\newcommand{\cm}{\mathcal{M}}
\end_inset

 
\begin_inset FormulaMacro
\newcommand{\cn}{\mathcal{N}}
\end_inset

 
\begin_inset FormulaMacro
\newcommand{\co}{\mathcal{O}}
\end_inset

 
\begin_inset FormulaMacro
\newcommand{\cp}{\mathcal{P}}
\end_inset

 
\begin_inset FormulaMacro
\newcommand{\cq}{\mathcal{Q}}
\end_inset

 
\begin_inset FormulaMacro
\newcommand{\calr}{\mathcal{R}}
\end_inset

 
\begin_inset FormulaMacro
\newcommand{\cs}{\mathcal{S}}
\end_inset

 
\begin_inset FormulaMacro
\newcommand{\ct}{\mathcal{T}}
\end_inset

 
\begin_inset FormulaMacro
\newcommand{\cu}{\mathcal{U}}
\end_inset

 
\begin_inset FormulaMacro
\newcommand{\cv}{\mathcal{V}}
\end_inset

 
\begin_inset FormulaMacro
\newcommand{\cw}{\mathcal{W}}
\end_inset

 
\begin_inset FormulaMacro
\newcommand{\cx}{\mathcal{X}}
\end_inset

 
\begin_inset FormulaMacro
\newcommand{\cy}{\mathcal{Y}}
\end_inset

 
\begin_inset FormulaMacro
\newcommand{\cz}{\mathcal{Z}}
\end_inset

 
\begin_inset FormulaMacro
\newcommand{\ind}[1]{1(#1)}
\end_inset

 
\begin_inset ERT
status collapsed

\begin_layout Plain Layout

%
\backslash
newcommand{
\backslash
pr}{P}
\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\begin_inset FormulaMacro
\newcommand{\pr}{\mathbb{P}}
\end_inset

 
\begin_inset FormulaMacro
\newcommand{\predsp}{\cy}
\end_inset

 
\begin_inset ERT
status collapsed

\begin_layout Plain Layout

%{
\backslash
hat{
\backslash
cy}}
\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\begin_inset FormulaMacro
\newcommand{\outsp}{\cy}
\end_inset


\end_layout

\begin_layout Standard
\begin_inset FormulaMacro
\newcommand{\prxy}{P_{\cx\times\cy}}
\end_inset

 
\begin_inset FormulaMacro
\newcommand{\prx}{P_{\cx}}
\end_inset

 
\begin_inset FormulaMacro
\newcommand{\prygivenx}{P_{\cy\mid\cx}}
\end_inset

 
\begin_inset ERT
status collapsed

\begin_layout Plain Layout

%
\backslash
newcommand{
\backslash
ex}{E}
\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\begin_inset FormulaMacro
\newcommand{\ex}{\mathbb{E}}
\end_inset

 
\begin_inset FormulaMacro
\newcommand{\var}{\textrm{Var}}
\end_inset

 
\begin_inset FormulaMacro
\newcommand{\cov}{\textrm{Cov}}
\end_inset

 
\begin_inset FormulaMacro
\newcommand{\sgn}{\textrm{sgn}}
\end_inset

 
\begin_inset FormulaMacro
\newcommand{\sign}{\textrm{sign}}
\end_inset

 
\begin_inset FormulaMacro
\newcommand{\kl}{\textrm{KL}}
\end_inset

 
\begin_inset FormulaMacro
\newcommand{\law}{\mathcal{L}}
\end_inset

 
\begin_inset FormulaMacro
\newcommand{\eps}{\varepsilon}
\end_inset

 
\begin_inset FormulaMacro
\newcommand{\as}{\textrm{ a.s.}}
\end_inset

 
\begin_inset FormulaMacro
\newcommand{\io}{\textrm{ i.o.}}
\end_inset

 
\begin_inset FormulaMacro
\newcommand{\ev}{\textrm{ ev.}}
\end_inset

 
\begin_inset FormulaMacro
\newcommand{\convd}{\stackrel{d}{\to}}
\end_inset

 
\begin_inset FormulaMacro
\newcommand{\eqd}{\stackrel{d}{=}}
\end_inset

 
\begin_inset FormulaMacro
\newcommand{\del}{\nabla}
\end_inset

 
\begin_inset FormulaMacro
\newcommand{\loss}{\ell}
\end_inset

 
\begin_inset FormulaMacro
\newcommand{\risk}{R}
\end_inset

 
\begin_inset FormulaMacro
\newcommand{\emprisk}{\hat{R}}
\end_inset

 
\begin_inset FormulaMacro
\newcommand{\lossfnl}{L}
\end_inset

 
\begin_inset FormulaMacro
\newcommand{\emplossfnl}{\hat{L}}
\end_inset

 
\begin_inset FormulaMacro
\newcommand{\empminimizer}[1]{\hat{#1}^{*}}
\end_inset

 
\begin_inset FormulaMacro
\newcommand{\minimizer}[1]{#1^{*}}
\end_inset


\begin_inset FormulaMacro
\newcommand{\optimizer}[1]{#1^{*}}
\end_inset

 
\begin_inset FormulaMacro
\newcommand{\etal}{\textrm{et. al.}}
\end_inset

 
\begin_inset FormulaMacro
\newcommand{\tr}{\operatorname{tr}}
\end_inset


\end_layout

\begin_layout Standard
\begin_inset FormulaMacro
\newcommand{\trace}{\operatorname{trace}}
\end_inset

 
\begin_inset FormulaMacro
\newcommand{\diag}{\text{diag}}
\end_inset

 
\begin_inset FormulaMacro
\newcommand{\rank}{\text{rank}}
\end_inset

 
\begin_inset FormulaMacro
\newcommand{\linspan}{\text{span}}
\end_inset

 
\begin_inset FormulaMacro
\newcommand{\spn}{\text{span}}
\end_inset

 
\begin_inset FormulaMacro
\newcommand{\proj}{\text{Proj}}
\end_inset

 
\begin_inset FormulaMacro
\newcommand{\argmax}{\operatornamewithlimits{arg\, max}}
{\text{argmax}}
\end_inset

 
\begin_inset FormulaMacro
\newcommand{\argmin}{\operatornamewithlimits{arg\, min}}
{\text{argmin}}
\end_inset


\end_layout

\begin_layout Standard
\begin_inset FormulaMacro
\newcommand{\bfx}{\mathbf{x}}
\end_inset

 
\begin_inset FormulaMacro
\newcommand{\bfy}{\mathbf{y}}
\end_inset

 
\begin_inset FormulaMacro
\newcommand{\bfl}{\mathbf{\lambda}}
\end_inset

 
\begin_inset FormulaMacro
\newcommand{\bfm}{\mathbf{\mu}}
\end_inset

 
\begin_inset FormulaMacro
\newcommand{\calL}{\mathcal{L}}
\end_inset


\end_layout

\begin_layout Standard
\begin_inset FormulaMacro
\newcommand{\vw}{\boldsymbol{w}}
\end_inset

 
\begin_inset FormulaMacro
\newcommand{\vx}{\boldsymbol{x}}
\end_inset

 
\begin_inset FormulaMacro
\newcommand{\vxi}{\boldsymbol{\xi}}
\end_inset

 
\begin_inset FormulaMacro
\newcommand{\valpha}{\boldsymbol{\alpha}}
\end_inset

 
\begin_inset FormulaMacro
\newcommand{\vbeta}{\boldsymbol{\beta}}
\end_inset

 
\begin_inset FormulaMacro
\newcommand{\vsigma}{\boldsymbol{\sigma}}
\end_inset


\begin_inset FormulaMacro
\newcommand{\vtheta}{\boldsymbol{\theta}}
\end_inset

 
\begin_inset FormulaMacro
\newcommand{\vd}{\boldsymbol{d}}
\end_inset

 
\begin_inset FormulaMacro
\newcommand{\vs}{\boldsymbol{s}}
\end_inset

 
\begin_inset FormulaMacro
\newcommand{\vt}{\boldsymbol{t}}
\end_inset

 
\begin_inset FormulaMacro
\newcommand{\vh}{\boldsymbol{h}}
\end_inset

 
\begin_inset FormulaMacro
\newcommand{\ve}{\boldsymbol{e}}
\end_inset

 
\begin_inset FormulaMacro
\newcommand{\vf}{\boldsymbol{f}}
\end_inset

 
\begin_inset FormulaMacro
\newcommand{\vg}{\boldsymbol{g}}
\end_inset

 
\begin_inset FormulaMacro
\newcommand{\vz}{\boldsymbol{z}}
\end_inset

 
\begin_inset FormulaMacro
\newcommand{\vk}{\boldsymbol{k}}
\end_inset

 
\begin_inset FormulaMacro
\newcommand{\va}{\boldsymbol{a}}
\end_inset

 
\begin_inset FormulaMacro
\newcommand{\vb}{\boldsymbol{b}}
\end_inset

 
\begin_inset FormulaMacro
\newcommand{\vv}{\boldsymbol{v}}
\end_inset

 
\begin_inset FormulaMacro
\newcommand{\vy}{\boldsymbol{y}}
\end_inset


\end_layout

\begin_layout Standard
\begin_inset FormulaMacro
\newcommand{\hil}{\ch}
\end_inset

 
\begin_inset FormulaMacro
\newcommand{\rkhs}{\hil}
\end_inset

 
\begin_inset FormulaMacro
\newcommand{\ber}{\text{Ber}}
\end_inset


\end_layout

\begin_layout Title
\begin_inset Formula $K$
\end_inset

-Means and Gaussian Mixture Models
\begin_inset Argument 1
status open

\begin_layout Plain Layout
DS-GA 1003 
\begin_inset Note Note
status open

\begin_layout Plain Layout
optional, use only with long paper titles
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Author
David Rosenberg 
\end_layout

\begin_layout Date
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
today
\end_layout

\end_inset


\end_layout

\begin_layout Institute
New York University
\end_layout

\begin_layout Standard
\begin_inset Note Note
status open

\begin_layout Plain Layout
\begin_inset ERT
status open

\begin_layout Plain Layout

Next time -- refer more to "components" than clusters (or maybe 'components'
 for the mixture model part, but clusters for the actual clustering alorithm
 k-means).
 talk about vector quantization
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Note Note
status open

\begin_layout Plain Layout
\begin_inset ERT
status open

\begin_layout Plain Layout

TODO: initialization of k-means actually can be very important.
  Introduce k-means++ for seeding (arthur et al 2007).
  Issue is it's slow; Refer to NIPS 2016 paper for a fast minibatch/MCMC
 approach.
 (fast and provably good seedings for k-means)
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Section
\begin_inset Formula $K$
\end_inset

-Means Clustering
\end_layout

\begin_layout Frame
\begin_inset Argument 4
status open

\begin_layout Plain Layout
Example: Old Faithful Geyser
\end_layout

\end_inset


\end_layout

\begin_layout Frame

\end_layout

\begin_deeper
\begin_layout Standard
\align center
\begin_inset Graphics
	filename ../Figures/clustering/oldfaithful.png
	lyxscale 20
	width 65text%

\end_inset


\end_layout

\begin_layout Itemize
Looks like two clusters.
\end_layout

\begin_layout Itemize
How to find these clusters algorithmically?
\end_layout

\end_deeper
\begin_layout Standard
\begin_inset Separator parbreak
\end_inset


\end_layout

\begin_layout Frame
\begin_inset Argument 4
status open

\begin_layout Plain Layout
\begin_inset Formula $k$
\end_inset

-Means: By Example
\end_layout

\end_inset


\end_layout

\begin_layout Frame

\end_layout

\begin_deeper
\begin_layout Itemize
Standardize the data.
\end_layout

\begin_layout Itemize
Choose two cluster centers.
\end_layout

\begin_layout Standard
\align center
\begin_inset Graphics
	filename ../Figures/clustering/faithful-9.1a.png
	lyxscale 50
	height 55theight%

\end_inset


\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
let
\backslash
thefootnote
\backslash
relax
\backslash
footnotetext{
\backslash
tiny{From Bishop's 
\backslash
emph{Pattern recognition and machine learning}, Figure 9.1(a).}}
\end_layout

\end_inset


\end_layout

\end_deeper
\begin_layout Frame

\end_layout

\begin_layout Standard
\begin_inset Separator parbreak
\end_inset


\end_layout

\begin_layout Frame
\begin_inset Argument 4
status open

\begin_layout Plain Layout
k-means: by example
\end_layout

\end_inset


\end_layout

\begin_layout Frame

\end_layout

\begin_deeper
\begin_layout Itemize
Assign each point to closest center.
\end_layout

\begin_layout Standard
\align center
\begin_inset Graphics
	filename ../Figures/clustering/faithful-9.1b.png
	lyxscale 50
	height 55theight%

\end_inset


\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
let
\backslash
thefootnote
\backslash
relax
\backslash
footnotetext{
\backslash
tiny{From Bishop's 
\backslash
emph{Pattern recognition and machine learning}, Figure 9.1(b).}}
\end_layout

\end_inset


\end_layout

\end_deeper
\begin_layout Standard
\begin_inset Separator parbreak
\end_inset


\end_layout

\begin_layout Frame
\begin_inset Argument 4
status open

\begin_layout Plain Layout
k-means: by example
\end_layout

\end_inset


\end_layout

\begin_layout Frame

\end_layout

\begin_deeper
\begin_layout Itemize
Compute new class centers.
\end_layout

\begin_layout Standard
\align center
\begin_inset Graphics
	filename ../Figures/clustering/faithful-9.1c.png
	lyxscale 50
	height 55theight%

\end_inset


\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
let
\backslash
thefootnote
\backslash
relax
\backslash
footnotetext{
\backslash
tiny{From Bishop's 
\backslash
emph{Pattern recognition and machine learning}, Figure 9.1(c).}}
\end_layout

\end_inset


\end_layout

\end_deeper
\begin_layout Standard
\begin_inset Separator parbreak
\end_inset


\end_layout

\begin_layout Frame
\begin_inset Argument 4
status open

\begin_layout Plain Layout
k-means: by example
\end_layout

\end_inset


\end_layout

\begin_layout Frame

\end_layout

\begin_deeper
\begin_layout Itemize
Assign points to closest center.
\end_layout

\begin_layout Standard
\align center
\begin_inset Graphics
	filename ../Figures/clustering/faithful-9.1d.png
	lyxscale 50
	height 55theight%

\end_inset


\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
let
\backslash
thefootnote
\backslash
relax
\backslash
footnotetext{
\backslash
tiny{From Bishop's 
\backslash
emph{Pattern recognition and machine learning}, Figure 9.1(d).}}
\end_layout

\end_inset


\end_layout

\end_deeper
\begin_layout Standard
\begin_inset Separator parbreak
\end_inset


\end_layout

\begin_layout Frame
\begin_inset Argument 4
status open

\begin_layout Plain Layout
k-means: by example
\end_layout

\end_inset


\end_layout

\begin_layout Frame

\end_layout

\begin_deeper
\begin_layout Itemize
Compute cluster centers.
\end_layout

\begin_layout Standard
\align center
\begin_inset Graphics
	filename ../Figures/clustering/faithful-9.1e.png
	lyxscale 50
	height 55theight%

\end_inset


\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
let
\backslash
thefootnote
\backslash
relax
\backslash
footnotetext{
\backslash
tiny{From Bishop's 
\backslash
emph{Pattern recognition and machine learning}, Figure 9.1(e).}}
\end_layout

\end_inset


\end_layout

\end_deeper
\begin_layout Standard
\begin_inset Separator parbreak
\end_inset


\end_layout

\begin_layout Frame
\begin_inset Argument 4
status open

\begin_layout Plain Layout
k-means: by example
\end_layout

\end_inset


\end_layout

\begin_layout Frame

\end_layout

\begin_deeper
\begin_layout Itemize
Iterate until convergence.
\end_layout

\begin_layout Standard
\align center
\begin_inset Graphics
	filename ../Figures/clustering/faithful-9.1i.png
	lyxscale 50
	height 55theight%

\end_inset


\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
let
\backslash
thefootnote
\backslash
relax
\backslash
footnotetext{
\backslash
tiny{From Bishop's 
\backslash
emph{Pattern recognition and machine learning}, Figure 9.1(i).}}
\end_layout

\end_inset


\end_layout

\end_deeper
\begin_layout Standard
\begin_inset Note Note
status open

\begin_layout Separator

\end_layout

\begin_layout Frame
\begin_inset Argument 4
status open

\begin_layout Plain Layout
k-means: formalization
\end_layout

\end_inset


\end_layout

\begin_layout Frame

\end_layout

\begin_deeper
\begin_layout Itemize
Dataset 
\begin_inset Formula $\cd=\left\{ x_{1},\ldots,x_{n}\right\} \in\reals^{d}$
\end_inset


\end_layout

\begin_deeper
\begin_layout Pause

\end_layout

\end_deeper
\begin_layout Itemize
Goal (version 1): Partition data into 
\begin_inset Formula $k$
\end_inset

 clusters.
\end_layout

\begin_deeper
\begin_layout Pause

\end_layout

\end_deeper
\begin_layout Itemize
Goal (version 2): Partition 
\begin_inset Formula $\reals^{d}$
\end_inset

 into 
\begin_inset Formula $k$
\end_inset

 regions.
\end_layout

\begin_deeper
\begin_layout Pause

\end_layout

\end_deeper
\begin_layout Itemize
Let 
\begin_inset Formula $\mu_{1},\ldots,$
\end_inset


\begin_inset Formula $\mu_{k}$
\end_inset

 denote cluster centers.
 
\end_layout

\end_deeper
\begin_layout Separator

\end_layout

\begin_layout Frame
\begin_inset Argument 4
status open

\begin_layout Plain Layout
k-means: formalization
\end_layout

\end_inset


\end_layout

\begin_layout Frame

\end_layout

\begin_deeper
\begin_layout Itemize
For each 
\begin_inset Formula $x_{i}$
\end_inset

, use a 
\series bold
one-hot encoding
\series default
 to designate membership:
\begin_inset Formula 
\[
r_{i}=\left(0,0,\ldots,0,0,1,0,0\right)\in\reals^{k}
\]

\end_inset


\end_layout

\begin_deeper
\begin_layout Pause

\end_layout

\end_deeper
\begin_layout Itemize
Let 
\begin_inset Formula 
\[
r_{ic}=\ind{x_{i}\mbox{ assigned to cluster }c}.
\]

\end_inset


\end_layout

\begin_deeper
\begin_layout Pause

\end_layout

\end_deeper
\begin_layout Itemize
Then
\begin_inset Formula 
\[
r_{i}=\left(r_{i1},r_{i2},\ldots,r_{ik}\right).
\]

\end_inset


\end_layout

\end_deeper
\begin_layout Separator

\end_layout

\begin_layout Frame
\begin_inset Argument 4
status open

\begin_layout Plain Layout
k-means: objective function
\end_layout

\end_inset


\end_layout

\begin_layout Frame

\end_layout

\begin_deeper
\begin_layout Itemize
Find cluster centers and cluster assignments minimizing
\begin_inset Formula 
\[
J(r,\mu)=\sum_{i=1}^{n}\sum_{c=1}^{k}r_{ic}\|x_{i}-\mu_{c}\|^{2}.
\]

\end_inset


\end_layout

\begin_deeper
\begin_layout Pause

\end_layout

\end_deeper
\begin_layout Itemize
Is objective function convex?
\end_layout

\begin_deeper
\begin_layout Pause

\end_layout

\end_deeper
\begin_layout Itemize
What's the domain of 
\begin_inset Formula $J$
\end_inset

?
\end_layout

\begin_deeper
\begin_layout Pause

\end_layout

\end_deeper
\begin_layout Itemize
\begin_inset Formula $r\in\left\{ 0,1\right\} ^{n\times k}$
\end_inset

, which is not a convex set...
\end_layout

\begin_deeper
\begin_layout Pause

\end_layout

\end_deeper
\begin_layout Itemize
So domain of 
\begin_inset Formula $J$
\end_inset

 is not convex 
\begin_inset Formula $\implies$
\end_inset

 
\begin_inset Formula $J$
\end_inset

 is not a convex function
\end_layout

\begin_deeper
\begin_layout Pause

\end_layout

\end_deeper
\begin_layout Itemize
\begin_inset Formula $k$
\end_inset

-means will not find global minimum of 
\begin_inset Formula $J(r,\mu)$
\end_inset

 
\begin_inset Note Note
status open

\begin_layout Pause

\end_layout

\begin_layout Itemize
Could replace 
\begin_inset Formula $\|\cdot\|^{2}$
\end_inset

 with something else:
\begin_inset Separator latexpar
\end_inset


\end_layout

\begin_deeper
\begin_layout Itemize
e.g.
 using 
\begin_inset Formula $\|\cdot\|$
\end_inset

 (or any distance metric) gives 
\series bold

\begin_inset Formula $k$
\end_inset

-medoids
\series default
.
\end_layout

\begin_layout Itemize
\begin_inset Formula $k$
\end_inset

-medoids chooses data points as cluster centers and minimizes sum of distances
 for any metric, rather than Euclidean distance
\end_layout

\end_deeper
\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Note Note
status open

\begin_layout Pause

\end_layout

\begin_layout Itemize
What if we did soft assignments? 
\begin_inset Formula $r_{ic}\in[0,1]$
\end_inset

?
\end_layout

\begin_layout Itemize
Then it's 
\series bold
biconvex:
\series default
 
\begin_inset Separator latexpar
\end_inset


\end_layout

\begin_deeper
\begin_layout Itemize
convex in 
\begin_inset Formula $r$
\end_inset

 with 
\begin_inset Formula $\mu$
\end_inset

 fixed
\end_layout

\begin_layout Itemize
convex in 
\begin_inset Formula $\mu$
\end_inset

 with 
\begin_inset Formula $r$
\end_inset

 fixed
\end_layout

\end_deeper
\end_inset


\end_layout

\end_deeper
\begin_layout Separator

\end_layout

\begin_layout Frame
\begin_inset Argument 4
status open

\begin_layout Plain Layout
k-means algorithm
\end_layout

\end_inset


\end_layout

\begin_layout Frame
\begin_inset Separator latexpar
\end_inset


\end_layout

\begin_deeper
\begin_layout Itemize
For fixed 
\begin_inset Formula $r$
\end_inset

 (cluster assignments), minimizing over 
\begin_inset Formula $\mu$
\end_inset

 is easy:
\begin_inset Formula 
\begin{eqnarray*}
J(r,\mu) & = & \sum_{i=1}^{n}\sum_{c=1}^{k}r_{ic}\|x_{i}-\mu_{c}\|^{2}\\
\pause & = & \sum_{c=1}^{k}\underbrace{\sum_{i=1}^{n}r_{ic}\|x_{i}-\mu_{c}\|^{2}}_{=J_{c}}\\
\pause J_{c}(\mu_{c}) & = & \sum_{\left\{ i\mid x_{i}\text{belongs to cluster }c\right\} }\|x_{i}-\mu_{c}\|^{2}\pause
\end{eqnarray*}

\end_inset


\end_layout

\begin_layout Itemize
\begin_inset Formula $J_{c}$
\end_inset

 is minimized by
\begin_inset Formula 
\[
\pause\mu_{c}=\text{mean}\left(\left\{ x_{i}\mid x_{i}\text{ belongs to cluster }c\right\} \right)
\]

\end_inset


\end_layout

\end_deeper
\begin_layout Separator

\end_layout

\begin_layout Frame
\begin_inset Argument 4
status open

\begin_layout Plain Layout
k-means algorithm
\end_layout

\end_inset


\end_layout

\begin_layout Frame
\begin_inset Separator latexpar
\end_inset


\end_layout

\begin_deeper
\begin_layout Itemize
For fixed 
\begin_inset Formula $\mu$
\end_inset

 (cluster centers), minimizing over 
\begin_inset Formula $r$
\end_inset

 is easy:
\begin_inset Formula 
\begin{eqnarray*}
J(r,\mu) & = & \sum_{i=1}^{n}\sum_{c=1}^{k}r_{ic}\|x_{i}-\mu_{c}\|^{2}
\end{eqnarray*}

\end_inset


\begin_inset Separator latexpar
\end_inset


\end_layout

\begin_deeper
\begin_layout Pause

\end_layout

\end_deeper
\begin_layout Itemize
For each 
\begin_inset Formula $i$
\end_inset

, exactly one of the following terms is nonzero:
\begin_inset Formula 
\[
r_{i1}\|x_{i}-\mu_{1}\|^{2},r_{i2}\|x_{i}-\mu_{2}\|^{2},\ldots,r_{ik}\|x_{i}-\mu_{k}\|^{2}
\]

\end_inset


\begin_inset Separator latexpar
\end_inset


\end_layout

\begin_deeper
\begin_layout Pause

\end_layout

\end_deeper
\begin_layout Itemize
Take
\begin_inset Formula 
\[
r_{ic}=\ind{c=\argmin_{j}\|x_{i}-\mu_{j}\|^{2}}
\]

\end_inset


\begin_inset Separator latexpar
\end_inset


\end_layout

\begin_deeper
\begin_layout Pause

\end_layout

\end_deeper
\begin_layout Itemize
That is, assign 
\begin_inset Formula $x_{i}$
\end_inset

 to cluster 
\begin_inset Formula $c$
\end_inset

 with minimum distance 
\begin_inset Formula 
\[
\|x_{i}-\mu_{c}\|^{2}
\]

\end_inset

 
\end_layout

\end_deeper
\begin_layout Separator

\end_layout

\begin_layout Frame
\begin_inset Argument 4
status open

\begin_layout Plain Layout
k-means algorithm (summary)
\end_layout

\end_inset


\end_layout

\begin_layout Frame
\begin_inset Separator latexpar
\end_inset


\end_layout

\begin_deeper
\begin_layout Itemize
We will use an 
\series bold
alternating minimization
\series default
 algorithm: 
\begin_inset Separator latexpar
\end_inset


\end_layout

\begin_deeper
\begin_layout Enumerate
Choose initial cluster centers 
\begin_inset Formula $\mu=\left(\mu_{1},\ldots,\mu_{k}\right)$
\end_inset

.
\begin_inset Separator latexpar
\end_inset


\end_layout

\begin_deeper
\begin_layout Itemize
e.g.
 choose 
\begin_inset Formula $k$
\end_inset

 randomly chosen data points
\end_layout

\begin_layout Pause

\end_layout

\end_deeper
\begin_layout Enumerate
Repeat
\begin_inset Separator latexpar
\end_inset


\end_layout

\begin_deeper
\begin_layout Enumerate
For given cluster centers, find optimal cluster assignments:
\begin_inset Formula 
\[
r_{ic}^{\text{new}}=\ind{c=\argmin_{j}\|x_{i}-\mu_{j}\|^{2}}
\]

\end_inset


\begin_inset Separator latexpar
\end_inset


\end_layout

\begin_deeper
\begin_layout Pause

\end_layout

\end_deeper
\begin_layout Enumerate
Given cluster assignments, find optimal cluster centers:
\begin_inset Formula 
\[
\mu_{c}^{\text{new}}=\argmin_{m\in\reals^{d}};\sum_{\left\{ i\mid r_{ic}=1\right\} }\|x_{i}-\mu_{c}\|^{2}
\]

\end_inset


\end_layout

\end_deeper
\end_deeper
\end_deeper
\begin_layout Separator

\end_layout

\begin_layout Frame
\begin_inset Argument 4
status open

\begin_layout Plain Layout
\begin_inset Formula $k$
\end_inset

-Means Algorithm: Convergence
\end_layout

\end_inset


\end_layout

\begin_layout Frame
\begin_inset Separator latexpar
\end_inset


\end_layout

\begin_deeper
\begin_layout Itemize
Note: Objective value never increases in an update.
\begin_inset Separator latexpar
\end_inset


\end_layout

\begin_deeper
\begin_layout Pause

\end_layout

\begin_layout Itemize
(Obvious: worst case, everything stays the same)
\end_layout

\end_deeper
\begin_layout Pause

\end_layout

\begin_layout Itemize
Consider the sequence of objective values: 
\begin_inset Formula $J_{1},J_{2},J_{3},\ldots$
\end_inset


\begin_inset Separator latexpar
\end_inset


\end_layout

\begin_deeper
\begin_layout Pause

\end_layout

\begin_layout Itemize
monotonically decreasing
\begin_inset Separator latexpar
\end_inset


\end_layout

\begin_deeper
\begin_layout Pause

\end_layout

\end_deeper
\begin_layout Itemize
bounded below by zero
\begin_inset Separator latexpar
\end_inset


\end_layout

\begin_deeper
\begin_layout Pause

\end_layout

\end_deeper
\end_deeper
\begin_layout Itemize
Therefore, 
\series bold

\begin_inset Formula $k$
\end_inset

-Means objective value converges
\series default
 to 
\begin_inset Formula $\inf_{t}J_{t}$
\end_inset

.
 
\begin_inset Note Note
status open

\begin_layout Pause

\end_layout

\begin_layout Itemize
Do the cluster assignments converge? The cluster centers?
\begin_inset Separator latexpar
\end_inset


\end_layout

\begin_deeper
\begin_layout Pause

\end_layout

\end_deeper
\begin_layout Itemize
In fact, convergence in a 
\series bold
finite number of steps
\series default
!
\end_layout

\end_inset


\begin_inset Separator latexpar
\end_inset


\end_layout

\begin_deeper
\begin_layout Pause

\end_layout

\end_deeper
\begin_layout Itemize

\series bold
Reminder
\series default
: May not converge to global minimizer.
\end_layout

\begin_layout Itemize
Best to repeat 
\begin_inset Formula $k$
\end_inset

-means several times, with different starting points
\end_layout

\end_deeper
\begin_layout Separator

\end_layout

\end_inset


\begin_inset Note Note
status collapsed

\begin_layout Separator

\end_layout

\begin_layout Frame
\begin_inset Argument 4
status open

\begin_layout Plain Layout
\begin_inset Formula $k$
\end_inset

-Means: Objective Function Convergence
\end_layout

\end_inset


\end_layout

\begin_layout Frame
\begin_inset Separator latexpar
\end_inset


\end_layout

\begin_deeper
\begin_layout Itemize
Blue circles after 
\series bold

\begin_inset Quotes eld
\end_inset

E
\begin_inset Quotes erd
\end_inset

 step
\series default
: assigning each point to a cluster
\end_layout

\begin_layout Itemize
Red circles after 
\series bold

\begin_inset Quotes eld
\end_inset

M
\begin_inset Quotes erd
\end_inset

 step
\series default
: recomputing the cluster centers
\end_layout

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename ../Figures/clustering/figure-9.2.png
	lyxscale 50
	height 45theight%

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
let
\backslash
thefootnote
\backslash
relax
\backslash
footnotetext{
\backslash
tiny{From Bishop's 
\backslash
emph{Pattern recognition and machine learning}, Figure 9.2.}}
\end_layout

\end_inset


\end_layout

\end_deeper
\begin_layout Separator

\end_layout

\end_inset


\begin_inset Separator latexpar
\end_inset


\end_layout

\begin_layout Frame
\begin_inset Argument 4
status open

\begin_layout Plain Layout
\begin_inset Formula $k$
\end_inset

-Means Algorithm: Standardizing the data
\end_layout

\end_inset


\end_layout

\begin_layout Frame
\begin_inset Separator latexpar
\end_inset


\end_layout

\begin_deeper
\begin_layout Itemize
Without standardizing:
\end_layout

\begin_layout Standard
\align center
\begin_inset Graphics
	filename ../Figures/clustering/oldfaithful-clusterNoRescale.png
	lyxscale 20
	width 65text%

\end_inset


\end_layout

\begin_layout Itemize
Blue and black show results of k-means clustering
\end_layout

\begin_layout Itemize
Wait time dominates the distance metric
\end_layout

\end_deeper
\begin_layout Standard
\begin_inset Separator parbreak
\end_inset


\end_layout

\begin_layout Frame
\begin_inset Argument 4
status open

\begin_layout Plain Layout
\begin_inset Formula $k$
\end_inset

-Means Algorithm: Standardizing the data
\end_layout

\end_inset


\end_layout

\begin_layout Frame
\begin_inset Separator latexpar
\end_inset


\end_layout

\begin_deeper
\begin_layout Itemize
With standardizing:
\end_layout

\begin_layout Standard
\align center
\begin_inset Graphics
	filename ../Figures/clustering/oldfaithful-clusterStandardize.png
	lyxscale 20
	width 65text%

\end_inset


\end_layout

\begin_layout Itemize
Note several points have been reassigned from black to blue cluster.
\end_layout

\end_deeper
\begin_layout Standard
\begin_inset Separator parbreak
\end_inset


\end_layout

\begin_layout Section
\begin_inset Formula $k$
\end_inset

-Means: Failure Cases
\end_layout

\begin_layout Frame
\begin_inset Argument 4
status open

\begin_layout Plain Layout
\begin_inset Formula $k$
\end_inset

-Means: Suboptimal Local Minimum
\end_layout

\end_inset


\end_layout

\begin_layout Frame
\begin_inset Separator latexpar
\end_inset


\end_layout

\begin_deeper
\begin_layout Itemize
The clustering for 
\begin_inset Formula $k=3$
\end_inset

 below is a local minimum, but suboptimal:
\end_layout

\begin_layout Standard
\align center
\begin_inset Graphics
	filename ../Figures/clustering/k-means-local-optimum.png
	lyxscale 50
	width 80text%

\end_inset


\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
let
\backslash
thefootnote
\backslash
relax
\backslash
footnotetext{
\backslash
tiny{From Sontag's DS-GA 1003, 2014, Lecture 8.}}
\end_layout

\end_inset


\end_layout

\end_deeper
\begin_layout Standard
\begin_inset Separator parbreak
\end_inset


\end_layout

\begin_layout Section
Gaussian Mixture Models
\end_layout

\begin_layout Frame
\begin_inset Argument 4
status open

\begin_layout Plain Layout
Probabilistic Model for Clustering
\end_layout

\end_inset


\end_layout

\begin_layout Frame
\begin_inset Separator latexpar
\end_inset


\end_layout

\begin_deeper
\begin_layout Itemize
Let's consider a 
\series bold
generative model
\series default
 for the data.
\end_layout

\begin_layout Itemize
Suppose 
\begin_inset Separator latexpar
\end_inset


\end_layout

\begin_deeper
\begin_layout Enumerate
There are 
\begin_inset Formula $k$
\end_inset

 clusters.
\end_layout

\begin_layout Enumerate
We have a probability density for each cluster.
\end_layout

\end_deeper
\begin_layout Itemize
Generate a point as follows
\begin_inset Separator latexpar
\end_inset


\end_layout

\begin_deeper
\begin_layout Enumerate
Choose a random cluster 
\begin_inset Formula $z\in\left\{ 1,2,\ldots,k\right\} $
\end_inset

.
 
\end_layout

\begin_layout Enumerate
Choose a point from the distribution for cluster 
\begin_inset Formula $Z$
\end_inset

.
 
\end_layout

\end_deeper
\end_deeper
\begin_layout Standard
\begin_inset Separator parbreak
\end_inset


\end_layout

\begin_layout Frame
\begin_inset Argument 4
status open

\begin_layout Plain Layout
Gaussian Mixture Model (
\begin_inset Formula $k=3$
\end_inset

)
\end_layout

\end_inset


\end_layout

\begin_layout Frame
\begin_inset Separator latexpar
\end_inset


\end_layout

\begin_deeper
\begin_layout Enumerate
Choose 
\begin_inset Formula $z\in\left\{ 1,2,3\right\} $
\end_inset

 with 
\begin_inset Formula $p(1)=p(2)=p(3)=\frac{1}{3}$
\end_inset

.
 
\end_layout

\begin_layout Enumerate
Choose 
\begin_inset Formula $x\mid z\sim\cn\left(X\mid\mu_{z},\Sigma_{z}\right)$
\end_inset

.
\end_layout

\begin_layout Standard
\align center
\begin_inset Graphics
	filename ../Figures/clustering/mixture-3-gaussians.png
	lyxscale 30
	width 70text%

\end_inset


\end_layout

\end_deeper
\begin_layout Standard
\begin_inset Separator parbreak
\end_inset


\end_layout

\begin_layout Standard
\begin_inset Separator parbreak
\end_inset


\end_layout

\begin_layout Frame
\begin_inset Argument 4
status open

\begin_layout Plain Layout
Gaussian Mixture Model Parameters (
\begin_inset Formula $k$
\end_inset

 Components)
\end_layout

\end_inset


\begin_inset Separator latexpar
\end_inset


\end_layout

\begin_deeper
\begin_layout Standard
\align center
\begin_inset Formula 
\begin{eqnarray*}
\text{Cluster probabilities}: &  & \pi=\left(\pi_{1},\ldots,\pi_{k}\right)\\
\text{Cluster means}: &  & \mu=\left(\mu_{1},\ldots,\mu_{k}\right)\\
\text{Cluster covariance matrices:} &  & \Sigma=\left(\Sigma_{1},\ldots\Sigma_{k}\right)
\end{eqnarray*}

\end_inset


\begin_inset Graphics
	filename ../Figures/clustering/mixture-3-gaussians.png
	lyxscale 20
	height 40theight%

\end_inset

 
\end_layout

\begin_layout Pause

\end_layout

\begin_layout Standard
For now, 
\series bold
suppose all these parameters are known
\series default
.
 
\begin_inset Newline newline
\end_inset

We'll discuss how to 
\series bold
learn
\series default
 or 
\series bold
estimate 
\series default
them later.
\end_layout

\end_deeper
\begin_layout Standard
\begin_inset Separator parbreak
\end_inset


\end_layout

\begin_layout Frame
\begin_inset Argument 4
status open

\begin_layout Plain Layout
Gaussian Mixture Model: Joint Distribution 
\end_layout

\end_inset


\end_layout

\begin_layout Frame
\begin_inset Separator latexpar
\end_inset


\end_layout

\begin_deeper
\begin_layout ColumnsTopAligned
\begin_inset Separator latexpar
\end_inset


\end_layout

\begin_deeper
\begin_layout Column
\begin_inset ERT
status open

\begin_layout Plain Layout

.25
\backslash
textwidth
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\align center
\begin_inset Graphics
	filename ../Figures/clustering/gmm-bayesnet.png
	lyxscale 30
	width 40col%

\end_inset


\end_layout

\begin_layout Pause

\end_layout

\begin_layout Column
\begin_inset ERT
status open

\begin_layout Plain Layout

.75
\backslash
textwidth
\end_layout

\end_inset


\end_layout

\begin_layout Itemize
Factorize the joint distribution:
\begin_inset Formula 
\begin{eqnarray*}
p(x,z) & = & p(z)p(x\mid z)\\
\pause & = & \pi_{z}\cn\left(x\mid\mu_{z},\Sigma_{z}\right)
\end{eqnarray*}

\end_inset


\begin_inset Separator latexpar
\end_inset


\end_layout

\begin_deeper
\begin_layout Pause

\end_layout

\begin_layout Itemize
\begin_inset Formula $\pi_{z}$
\end_inset

 is probability of choosing cluster 
\begin_inset Formula $z$
\end_inset

.
\begin_inset Separator latexpar
\end_inset


\end_layout

\begin_deeper
\begin_layout Pause

\end_layout

\end_deeper
\begin_layout Itemize
\begin_inset Formula $x\mid z$
\end_inset

 has distribution 
\begin_inset Formula $\cn(\mu_{z},\Sigma_{z})$
\end_inset

.
\begin_inset Separator latexpar
\end_inset


\end_layout

\begin_deeper
\begin_layout Pause

\end_layout

\end_deeper
\begin_layout Itemize
\begin_inset Formula $z$
\end_inset

 corresponding to 
\begin_inset Formula $x$
\end_inset

 is the true cluster assignment.
 
\end_layout

\end_deeper
\end_deeper
\begin_layout Pause

\end_layout

\begin_layout Itemize
Suppose we know the model parameters 
\begin_inset Formula $\pi_{z},\mu_{z},\Sigma_{z}$
\end_inset

.
\end_layout

\begin_layout Pause

\end_layout

\begin_layout Itemize
Then we can easily compute the joint 
\begin_inset Formula $p(x,z)$
\end_inset

.
\end_layout

\end_deeper
\begin_layout Standard
\begin_inset Note Note
status collapsed

\begin_layout Separator

\end_layout

\begin_layout Frame
\begin_inset Argument 4
status open

\begin_layout Plain Layout
Latent Variable Model 
\end_layout

\end_inset


\end_layout

\begin_layout Frame
\begin_inset Separator latexpar
\end_inset


\end_layout

\begin_deeper
\begin_layout ColumnsTopAligned
\begin_inset Separator latexpar
\end_inset


\end_layout

\begin_deeper
\begin_layout Column
\begin_inset ERT
status open

\begin_layout Plain Layout

.25
\backslash
textwidth
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename ../Figures/clustering/gmm-bayesnet.png
	lyxscale 30
	width 60col%

\end_inset

 
\end_layout

\begin_layout Column
\begin_inset ERT
status open

\begin_layout Plain Layout

.75
\backslash
textwidth
\end_layout

\end_inset


\end_layout

\begin_layout Itemize
Back in reality, we observe 
\begin_inset Formula $X$
\end_inset

, not 
\begin_inset Formula $\left(X,Z\right)$
\end_inset

.
\begin_inset Separator latexpar
\end_inset


\end_layout

\begin_deeper
\begin_layout Pause

\end_layout

\end_deeper
\begin_layout Itemize
\begin_inset Formula $Z$
\end_inset

 is called a 
\series bold
hidden
\series default
 
\series bold
variable
\series default
.
\end_layout

\begin_layout Itemize
Models with hidden variables are called 
\series bold
latent variable models
\series default
.
 
\begin_inset Separator latexpar
\end_inset


\end_layout

\begin_deeper
\begin_layout Pause

\end_layout

\end_deeper
\end_deeper
\end_deeper
\begin_layout Separator

\end_layout

\end_inset


\begin_inset Separator latexpar
\end_inset


\end_layout

\begin_layout Frame
\begin_inset Argument 4
status open

\begin_layout Plain Layout
Latent Variable Model 
\end_layout

\end_inset


\end_layout

\begin_layout Frame
\begin_inset Separator latexpar
\end_inset


\end_layout

\begin_deeper
\begin_layout Itemize
We observe 
\begin_inset Formula $x$
\end_inset

.
\end_layout

\begin_layout Itemize
We don't observe 
\begin_inset Formula $z$
\end_inset

.
 (Cluster assignment).
\begin_inset Separator latexpar
\end_inset


\end_layout

\begin_deeper
\begin_layout Pause

\end_layout

\end_deeper
\begin_layout Itemize
Cluster assignment 
\begin_inset Formula $z$
\end_inset

 is called a 
\series bold
hidden
\series default
 
\series bold
variable
\series default
 or 
\series bold
latent variable
\series default
.
\begin_inset Separator latexpar
\end_inset


\end_layout

\begin_deeper
\begin_layout Pause

\end_layout

\end_deeper
\begin_layout Definition
A
\series bold
 latent variable model 
\series default
is a probability model for which certain variables are never observed.
\begin_inset Separator latexpar
\end_inset


\end_layout

\begin_deeper
\begin_layout Pause

\end_layout

\end_deeper
\begin_layout Standard
e.g.
 The Gaussian mixture model is a latent variable model.
\end_layout

\end_deeper
\begin_layout Standard
\begin_inset Separator parbreak
\end_inset


\end_layout

\begin_layout Frame
\begin_inset Argument 4
status open

\begin_layout Plain Layout
The GMM 
\begin_inset Quotes eld
\end_inset

Inference
\begin_inset Quotes erd
\end_inset

 Problem
\end_layout

\end_inset


\end_layout

\begin_layout Frame
\begin_inset Separator latexpar
\end_inset


\end_layout

\begin_deeper
\begin_layout Itemize
We observe 
\begin_inset Formula $x$
\end_inset

.
 We want to know 
\begin_inset Formula $z$
\end_inset

.
\begin_inset Separator latexpar
\end_inset


\end_layout

\begin_deeper
\begin_layout Pause

\end_layout

\end_deeper
\begin_layout Itemize
The conditional distribution of the cluster 
\begin_inset Formula $z$
\end_inset

 given 
\begin_inset Formula $x$
\end_inset

 is
\begin_inset Formula 
\[
p(z\mid x)=p(x,z)/p(x)
\]

\end_inset


\begin_inset Note Note
status open

\begin_layout Plain Layout
Could say: can't compute this because 
\begin_inset Formula $p(x)$
\end_inset

 is hard.
 But we don't actually need 
\begin_inset Formula $p(x)$
\end_inset

.
 Since 
\begin_inset Formula $p(z\mid x)\propto p(x,z)$
\end_inset

, which is easy.
 And we can just renormalize over 
\begin_inset Formula $z$
\end_inset

, which is a simple sum for discrete 
\begin_inset Formula $z$
\end_inset

.
\end_layout

\end_inset


\begin_inset Separator latexpar
\end_inset


\end_layout

\begin_deeper
\begin_layout Pause

\end_layout

\end_deeper
\begin_layout Itemize
The conditional distribution is a
\series bold
 soft assignment 
\series default
to clusters.
\begin_inset Separator latexpar
\end_inset


\end_layout

\begin_deeper
\begin_layout Pause

\end_layout

\end_deeper
\begin_layout Itemize
A 
\series bold
hard assignment 
\series default
is
\begin_inset Formula 
\[
z^{*}=\argmin_{z\in\left\{ 1,\ldots,k\right\} }p(z\mid x).
\]

\end_inset


\begin_inset Separator latexpar
\end_inset


\end_layout

\begin_deeper
\begin_layout Pause

\end_layout

\end_deeper
\begin_layout Itemize
So if we have the model, clustering is trival.
\end_layout

\end_deeper
\begin_layout Standard
\begin_inset Separator parbreak
\end_inset


\end_layout

\begin_layout Section
Mixture Models
\end_layout

\begin_layout Frame
\begin_inset Argument 4
status open

\begin_layout Plain Layout
Gaussian Mixture Model: Marginal Distribution
\end_layout

\end_inset


\end_layout

\begin_layout Frame
\begin_inset Separator latexpar
\end_inset


\end_layout

\begin_deeper
\begin_layout Itemize
The 
\series bold
marginal distribution
\series default
 for a single observation 
\begin_inset Formula $x$
\end_inset

 is
\series bold

\begin_inset Formula 
\begin{eqnarray*}
p(x) & = & \sum_{z=1}^{k}p(x,z)\\
\pause & = & \sum_{z=1}^{k}\pi_{z}\cn\left(x\mid\mu_{z},\Sigma_{z}\right)
\end{eqnarray*}

\end_inset


\series default

\begin_inset Separator latexpar
\end_inset


\end_layout

\begin_deeper
\begin_layout Pause

\end_layout

\end_deeper
\begin_layout Itemize
Note that 
\begin_inset Formula $p(x)$
\end_inset

 is a convex combination of probability densities.
 
\begin_inset Separator latexpar
\end_inset


\end_layout

\begin_deeper
\begin_layout Pause

\end_layout

\end_deeper
\begin_layout Itemize
This is a common form for a probability model...
\end_layout

\end_deeper
\begin_layout Standard
\begin_inset Separator parbreak
\end_inset


\end_layout

\begin_layout Frame
\begin_inset Argument 4
status open

\begin_layout Plain Layout
Mixture Distributions (or Mixture Models)
\end_layout

\end_inset


\end_layout

\begin_layout Frame
\begin_inset Separator latexpar
\end_inset


\end_layout

\begin_deeper
\begin_layout Definition
A probability density 
\begin_inset Formula $p(x)$
\end_inset

 represents a 
\series bold
mixture distribution 
\series default
or 
\series bold
mixture model, 
\series default
if we can write it as a 
\series bold
convex combination
\series default
 of probability densities.
 That is, 
\begin_inset Formula 
\[
p(x)=\sum_{i=1}^{k}w_{i}p_{i}(x),
\]

\end_inset

where 
\begin_inset Formula $w_{i}\ge0$
\end_inset

, 
\begin_inset Formula $\sum_{i=1}^{k}w_{i}=1$
\end_inset

, and each 
\begin_inset Formula $p_{i}$
\end_inset

 is a probability density.
\begin_inset Separator latexpar
\end_inset


\end_layout

\begin_deeper
\begin_layout Pause

\end_layout

\end_deeper
\begin_layout Itemize
In our Gaussian mixture model, 
\begin_inset Formula $x$
\end_inset

 has a 
\series bold
mixture distribution
\series default
.
 
\begin_inset Separator latexpar
\end_inset


\end_layout

\begin_deeper
\begin_layout Pause

\end_layout

\end_deeper
\begin_layout Itemize
More constructively, let 
\begin_inset Formula $S$
\end_inset

 be a set of probability distributions:
\begin_inset Separator latexpar
\end_inset


\end_layout

\begin_deeper
\begin_layout Enumerate
Choose a distribution randomly from 
\begin_inset Formula $S$
\end_inset

.
\end_layout

\begin_layout Enumerate
Sample 
\begin_inset Formula $x$
\end_inset

 from the chosen distribution.
\end_layout

\end_deeper
\begin_layout Itemize
Then 
\begin_inset Formula $x$
\end_inset

 has a mixture distribution.
\end_layout

\end_deeper
\begin_layout Standard
\begin_inset Separator parbreak
\end_inset


\end_layout

\begin_layout Section
Learning in Gaussian Mixture Models
\end_layout

\begin_layout Standard
\begin_inset Separator parbreak
\end_inset


\end_layout

\begin_layout Frame
\begin_inset Argument 4
status open

\begin_layout Plain Layout
The GMM 
\begin_inset Quotes eld
\end_inset

Learning
\begin_inset Quotes erd
\end_inset

 Problem
\end_layout

\end_inset


\begin_inset Separator latexpar
\end_inset


\end_layout

\begin_deeper
\begin_layout Itemize
Given data 
\begin_inset Formula $x_{1},\ldots,x_{n}$
\end_inset

 drawn from a GMM,
\end_layout

\begin_layout Itemize
Estimate the parameters: 
\begin_inset Formula 
\begin{eqnarray*}
\text{Cluster probabilities}: &  & \pi=\left(\pi_{1},\ldots,\pi_{k}\right)\\
\text{Cluster means}: &  & \mu=\left(\mu_{1},\ldots,\mu_{k}\right)\\
\text{Cluster covariance matrices:} &  & \Sigma=\left(\Sigma_{1},\ldots\Sigma_{k}\right)
\end{eqnarray*}

\end_inset


\begin_inset Separator latexpar
\end_inset


\end_layout

\begin_deeper
\begin_layout Pause

\end_layout

\end_deeper
\begin_layout Itemize
Once we have the parameters, we're done.
 
\begin_inset Separator latexpar
\end_inset


\end_layout

\begin_deeper
\begin_layout Pause

\end_layout

\end_deeper
\begin_layout Itemize
Just do 
\begin_inset Quotes eld
\end_inset

inference
\begin_inset Quotes erd
\end_inset

 to get cluster assignments.
\end_layout

\end_deeper
\begin_layout Standard
\begin_inset Note Note
status open

\begin_layout Separator

\end_layout

\begin_layout Frame
\begin_inset Argument 4
status open

\begin_layout Plain Layout
Estimating/Learning the Gaussian Mixture Model
\end_layout

\end_inset


\begin_inset Separator latexpar
\end_inset


\end_layout

\begin_deeper
\begin_layout Itemize
One approach to learning in probabilistic models is 
\series bold
maximum likelihood
\series default

\begin_inset Separator latexpar
\end_inset


\end_layout

\begin_deeper
\begin_layout Itemize
find parameter values that give 
\series bold
observed data 
\series default
the
\series bold
 highest likelihood
\series default
.
\end_layout

\begin_layout Pause

\end_layout

\end_deeper
\begin_layout Itemize
Let 
\begin_inset Formula $\theta=\left(\pi,\mu,\Sigma\right)$
\end_inset

 be the parameters for GMM.
\end_layout

\end_deeper
\begin_layout Separator

\end_layout

\end_inset


\begin_inset Separator latexpar
\end_inset


\end_layout

\begin_layout Standard
\begin_inset Note Note
status collapsed

\begin_layout Pause

\end_layout

\begin_layout Itemize
Observed likelihood for 
\begin_inset Formula $\cd=\left(x_{1},\ldots,x_{n}\right)$
\end_inset

 is
\begin_inset Formula 
\[
p(\cd)=\prod_{i=1}^{n}p(x_{i})=\prod_{i=1}^{n}\sum_{z=1}^{k}p(x_{i},z)\pause=\prod_{i=1}^{n}\sum_{z=1}^{k}\pi_{z}\cn\left(x\mid\mu_{z},\Sigma_{z}\right)
\]

\end_inset


\begin_inset Separator latexpar
\end_inset


\end_layout

\begin_deeper
\begin_layout Pause

\end_layout

\end_deeper
\begin_layout Itemize
In principle, just need to find
\begin_inset Formula 
\[
\argmax_{\pi,\mu,\Sigma}\prod_{i=1}^{n}\sum_{z=1}^{k}\pi_{z}\cn\left(x\mid\mu_{z},\Sigma_{z}\right).
\]

\end_inset


\begin_inset Separator latexpar
\end_inset


\end_layout

\begin_deeper
\begin_layout Pause

\end_layout

\end_deeper
\begin_layout Itemize
Unfortunately, this is very difficult.
\end_layout

\end_inset


\end_layout

\begin_layout Frame
\begin_inset Argument 4
status open

\begin_layout Plain Layout
Estimating/Learning the Gaussian Mixture Model
\end_layout

\end_inset


\begin_inset Separator latexpar
\end_inset


\end_layout

\begin_deeper
\begin_layout Itemize
One approach to learning is 
\series bold
maximum likelihood
\series default

\begin_inset Separator latexpar
\end_inset


\end_layout

\begin_deeper
\begin_layout Itemize
find parameter values that give 
\series bold
observed data 
\series default
the
\series bold
 highest likelihood
\series default
.
\end_layout

\end_deeper
\begin_layout Itemize
The model likelihood for 
\begin_inset Formula $\cd=\left\{ x_{1},\ldots,x_{n}\right\} $
\end_inset

 is
\begin_inset Formula 
\begin{eqnarray*}
L(\pi,\mu,\Sigma) & = & \prod_{i=1}^{n}p(x_{i})\\
\pause & = & \prod_{i=1}^{n}\sum_{z=1}^{k}\pi_{z}\cn\left(x_{i}\mid\mu_{z},\Sigma_{z}\right).
\end{eqnarray*}

\end_inset


\begin_inset Separator latexpar
\end_inset


\end_layout

\begin_deeper
\begin_layout Pause

\end_layout

\end_deeper
\begin_layout Itemize
As usual, we'll take our objective function to be the log of this:
\begin_inset Formula 
\begin{eqnarray*}
J(\pi,\mu,\Sigma) & = & \sum_{i=1}^{n}\log\left\{ \sum_{z=1}^{k}\pi_{z}\cn\left(x_{i}\mid\mu_{z},\Sigma_{z}\right)\right\} 
\end{eqnarray*}

\end_inset

 
\end_layout

\end_deeper
\begin_layout Standard
\begin_inset Separator parbreak
\end_inset


\end_layout

\begin_layout Standard
\begin_inset Note Note
status open

\begin_layout Plain Layout
Point of the next slide is to illustate that the sum blocks the log from
 simplifying things (the log and the exp canceling out)
\end_layout

\end_inset


\end_layout

\begin_layout Frame
\begin_inset Argument 4
status open

\begin_layout Plain Layout
Properties of the GMM Log-Likelihood
\end_layout

\end_inset


\begin_inset Separator latexpar
\end_inset


\end_layout

\begin_deeper
\begin_layout Itemize
GMM log-likelihood:
\begin_inset Formula 
\begin{eqnarray*}
J(\pi,\mu,\Sigma) & = & \sum_{i=1}^{n}\log\left\{ \sum_{z=1}^{k}\pi_{z}\cn\left(x_{i}\mid\mu_{z},\Sigma_{z}\right)\right\} 
\end{eqnarray*}

\end_inset


\begin_inset Separator latexpar
\end_inset


\end_layout

\begin_deeper
\begin_layout Pause

\end_layout

\end_deeper
\begin_layout Itemize
Let's compare to the log-likelihood for a single Gaussian:
\begin_inset Formula 
\begin{eqnarray*}
\pause &  & \sum_{i=1}^{n}\log\cn\left(x_{i}\mid\mu,\Sigma\right)\\
\pause & = & -\frac{nd}{2}\log\left(2\pi\right)-\frac{n}{2}\log\left|\Sigma\right|-\frac{1}{2}\sum_{i=1}^{n}(x_{i}-\mu)'\Sigma^{-1}(x_{i}-\mu)
\end{eqnarray*}

\end_inset


\begin_inset Separator latexpar
\end_inset


\end_layout

\begin_deeper
\begin_layout Pause

\end_layout

\end_deeper
\begin_layout Itemize
For a single Gaussian, the 
\begin_inset Formula $\log$
\end_inset

 cancels the 
\begin_inset Formula $\exp$
\end_inset

 in the Gaussian density.
\begin_inset Separator latexpar
\end_inset


\end_layout

\begin_deeper
\begin_layout Itemize
\begin_inset Formula $\implies$
\end_inset

 Things simplify a lot.
\end_layout

\begin_layout Pause

\end_layout

\end_deeper
\begin_layout Itemize
For the GMM, the sum inside the 
\begin_inset Formula $\log$
\end_inset

 prevents this cancellation.
\begin_inset Separator latexpar
\end_inset


\end_layout

\begin_deeper
\begin_layout Itemize
\begin_inset Formula $\implies$
\end_inset

 Expression more complicated.
 No closed form expression for MLE.
\end_layout

\end_deeper
\end_deeper
\begin_layout Standard
\begin_inset Separator parbreak
\end_inset


\end_layout

\begin_layout Section
Issues with MLE for GMM
\end_layout

\begin_layout Frame
\begin_inset Argument 4
status open

\begin_layout Plain Layout
Identifiability Issues for GMM
\end_layout

\end_inset


\begin_inset Separator latexpar
\end_inset


\end_layout

\begin_deeper
\begin_layout Itemize
Suppose we have found parameters 
\begin_inset Formula 
\begin{eqnarray*}
\text{Cluster probabilities}: &  & \pi=\left(\pi_{1},\ldots,\pi_{k}\right)\\
\text{Cluster means}: &  & \mu=\left(\mu_{1},\ldots,\mu_{k}\right)\\
\text{Cluster covariance matrices:} &  & \Sigma=\left(\Sigma_{1},\ldots\Sigma_{k}\right)
\end{eqnarray*}

\end_inset

 that are at a local minimum.
\end_layout

\begin_layout Pause

\end_layout

\begin_layout Itemize
What happens if we shuffle the clusters? e.g.
 Switch the labels for clusters 1 and 2.
\end_layout

\begin_layout Pause

\end_layout

\begin_layout Itemize
We'll get the same likelihood.
 How many such equivalent settings are there?
\end_layout

\begin_layout Pause

\end_layout

\begin_layout Itemize
Assuming all clusters are distinct, there are 
\begin_inset Formula $k!$
\end_inset

 equivalent solutions.
\end_layout

\begin_layout Pause

\end_layout

\begin_layout Itemize
Not a problem per se, but something to be aware of.
\end_layout

\end_deeper
\begin_layout Standard
\begin_inset Separator parbreak
\end_inset


\end_layout

\begin_layout Frame
\begin_inset Argument 4
status open

\begin_layout Plain Layout
Singularities for GMM
\end_layout

\end_inset


\begin_inset Separator latexpar
\end_inset


\end_layout

\begin_deeper
\begin_layout Itemize
Consider the following GMM for 7 data points:
\end_layout

\begin_layout Standard
\align center
\begin_inset Graphics
	filename ../Figures/clustering/gmm-singularity.png
	lyxscale 50
	height 40theight%

\end_inset


\end_layout

\begin_layout Pause

\end_layout

\begin_layout Itemize
Let 
\begin_inset Formula $\sigma^{2}$
\end_inset

 be the variance of the skinny component.
\end_layout

\begin_layout Itemize
What happens to the likelihood as 
\begin_inset Formula $\sigma^{2}\to0$
\end_inset

?
\begin_inset Separator latexpar
\end_inset


\end_layout

\begin_deeper
\begin_layout Pause

\end_layout

\end_deeper
\begin_layout Itemize
In practice, we end up in local minima that do not have this problem.
\begin_inset Separator latexpar
\end_inset


\end_layout

\begin_deeper
\begin_layout Itemize
(Provable under mild conditions – see lecture on general EM.)
\end_layout

\begin_layout Pause

\end_layout

\end_deeper
\begin_layout Itemize
Bayesian approach or regularization will also solve the problem.
\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
let
\backslash
thefootnote
\backslash
relax
\backslash
footnotetext{
\backslash
tiny{From Bishop's 
\backslash
emph{Pattern recognition and machine learning}, Figure 9.7.}}
\end_layout

\end_inset


\end_layout

\end_deeper
\begin_layout Standard
\begin_inset Separator parbreak
\end_inset


\end_layout

\begin_layout Standard
\begin_inset Note Note
status open

\begin_layout Plain Layout
Really need a reference or something to see if this thing actually even
 works...
 
\end_layout

\end_inset


\end_layout

\begin_layout Frame
\begin_inset Argument 4
status open

\begin_layout Plain Layout
Gradient Descent / SGD for GMM
\end_layout

\end_inset


\begin_inset Separator latexpar
\end_inset


\end_layout

\begin_deeper
\begin_layout Itemize
What about running gradient descent or SGD on
\begin_inset Formula 
\begin{eqnarray*}
J(\pi,\mu,\Sigma) & = & -\sum_{i=1}^{n}\log\left\{ \sum_{z=1}^{k}\pi_{z}\cn\left(x_{i}\mid\mu_{z},\Sigma_{z}\right)\right\} ?
\end{eqnarray*}

\end_inset


\end_layout

\begin_deeper
\begin_layout Pause

\end_layout

\end_deeper
\begin_layout Itemize
Can be done – but need to be clever about it.
\end_layout

\begin_deeper
\begin_layout Pause

\end_layout

\end_deeper
\begin_layout Itemize
Each matrix 
\begin_inset Formula $\Sigma_{1},\ldots,\Sigma_{k}$
\end_inset

 has to be positive semidefinite.
\end_layout

\begin_deeper
\begin_layout Pause

\end_layout

\end_deeper
\begin_layout Itemize
How to maintain that constraint?
\end_layout

\begin_deeper
\begin_layout Pause

\end_layout

\begin_layout Itemize
Rewrite 
\begin_inset Formula $\Sigma_{i}=M_{i}M_{i}^{T}$
\end_inset

, where 
\begin_inset Formula $M_{i}$
\end_inset

 is an unconstrained matrix.
 
\end_layout

\begin_deeper
\begin_layout Pause

\end_layout

\end_deeper
\begin_layout Itemize
Then 
\begin_inset Formula $\Sigma_{i}$
\end_inset

 is positive semidefinite.
 
\end_layout

\begin_deeper
\begin_layout Pause

\end_layout

\end_deeper
\end_deeper
\begin_layout Itemize
But we actually prefer positive definite, to avoid singularities.
\end_layout

\end_deeper
\begin_layout Standard
\begin_inset Separator parbreak
\end_inset


\end_layout

\begin_layout Frame
\begin_inset Argument 4
status open

\begin_layout Plain Layout
Cholesky Decomposition for SPD Matrices
\end_layout

\end_inset


\begin_inset Separator latexpar
\end_inset


\end_layout

\begin_deeper
\begin_layout Theorem
Every symmetric positive definite matrix 
\begin_inset Formula $A\in\reals^{d\times d}$
\end_inset

 has a unique 
\series bold
Cholesky decomposition
\series default
:
\begin_inset Formula 
\[
A=LL^{T},
\]

\end_inset

where 
\begin_inset Formula $L$
\end_inset

 a 
\series bold
lower triangular matrix
\series default
 with positive diagonal elements.
\begin_inset Separator latexpar
\end_inset


\end_layout

\begin_deeper
\begin_layout Pause

\end_layout

\end_deeper
\begin_layout Itemize
A lower triangular matrix has half the number of parameters.
 
\begin_inset Separator latexpar
\end_inset


\end_layout

\begin_deeper
\begin_layout Pause

\end_layout

\end_deeper
\begin_layout Itemize
Symmetric positive definite is better because avoids singularities.
\begin_inset Separator latexpar
\end_inset


\end_layout

\begin_deeper
\begin_layout Pause

\end_layout

\end_deeper
\begin_layout Itemize
Requires a non-negativity constraint on diagonal elements.
\begin_inset Separator latexpar
\end_inset


\end_layout

\begin_deeper
\begin_layout Pause

\end_layout

\begin_layout Itemize
e.g.
 Use projected SGD method like we did for the Lasso.
\end_layout

\end_deeper
\end_deeper
\begin_layout Standard
\begin_inset Separator parbreak
\end_inset


\end_layout

\begin_layout Section
The EM Algorithm for GMM
\end_layout

\begin_layout Frame
\begin_inset Argument 4
status open

\begin_layout Plain Layout
MLE for Gaussian Model
\end_layout

\end_inset


\begin_inset Separator latexpar
\end_inset


\end_layout

\begin_deeper
\begin_layout Itemize
Let's start by considering the MLE for the Gaussian model.
\end_layout

\begin_layout Itemize
For data 
\begin_inset Formula $\cd=\left\{ x_{1},\ldots,x_{n}\right\} $
\end_inset

, the log likelihood is given by
\begin_inset Formula 
\[
\sum_{i=1}^{n}\log\cn\left(x_{i}\mid\mu,\Sigma\right)=-\frac{nd}{2}\log\left(2\pi\right)-\frac{n}{2}\log\left|\Sigma\right|-\frac{1}{2}\sum_{i=1}^{n}(x_{i}-\mu)'\Sigma^{-1}(x_{i}-\mu).
\]

\end_inset


\begin_inset Separator latexpar
\end_inset


\end_layout

\begin_deeper
\begin_layout Pause

\end_layout

\end_deeper
\begin_layout Itemize
With some calculus, we find that the MLE parameters are
\begin_inset Formula 
\begin{eqnarray*}
\mu_{\text{MLE}} & = & \frac{1}{n}\sum_{i=1}^{n}x_{i}\\
\pause\Sigma_{\text{MLE}} & = & \frac{1}{n}\sum_{i=1}^{n}\left(x_{i}-\mu_{\text{MLE}}\right)\left(x_{i}-\mu_{\text{MLE}}\right)^{T}
\end{eqnarray*}

\end_inset


\begin_inset Separator latexpar
\end_inset


\end_layout

\begin_deeper
\begin_layout Pause

\end_layout

\end_deeper
\begin_layout Itemize
For GMM, If we knew the cluster assignment 
\begin_inset Formula $z_{i}$
\end_inset

 for each 
\begin_inset Formula $x_{i}$
\end_inset

, 
\begin_inset Separator latexpar
\end_inset


\end_layout

\begin_deeper
\begin_layout Itemize
we could compute the MLEs for each cluster.
 
\end_layout

\end_deeper
\end_deeper
\begin_layout Standard
\begin_inset Separator parbreak
\end_inset


\end_layout

\begin_layout Frame
\begin_inset Argument 4
status open

\begin_layout Plain Layout
Cluster Responsibilities: Some New Notation
\end_layout

\end_inset


\end_layout

\begin_layout Frame
\begin_inset Separator latexpar
\end_inset


\end_layout

\begin_deeper
\begin_layout Itemize
Denote the probability that observed value 
\begin_inset Formula $x_{i}$
\end_inset

 comes from cluster 
\begin_inset Formula $j$
\end_inset

 by
\begin_inset Formula 
\[
\gamma_{i}^{j}=\pr\left(Z=j\mid X=x_{i}\right).
\]

\end_inset


\begin_inset Separator latexpar
\end_inset


\end_layout

\begin_deeper
\begin_layout Pause

\end_layout

\end_deeper
\begin_layout Itemize
The 
\series bold
responsibility 
\series default
that cluster 
\begin_inset Formula $j$
\end_inset

 takes for observation 
\begin_inset Formula $x_{i}$
\end_inset

.
\begin_inset Separator latexpar
\end_inset


\end_layout

\begin_deeper
\begin_layout Pause

\end_layout

\end_deeper
\begin_layout Itemize
Computationally, 
\begin_inset Formula 
\begin{eqnarray*}
\gamma_{i}^{j} & = & \pr\left(Z=j\mid X=x_{i}\right).\\
\pause & = & p\left(Z=j,X=x_{i}\right)/p(x)\\
\pause & = & \frac{\pi_{j}\cn\left(x_{i}\mid\mu_{j},\Sigma_{j}\right)}{\sum_{c=1}^{k}\pi_{c}\cn\left(x_{i}\mid\mu_{c},\Sigma_{c}\right)}
\end{eqnarray*}

\end_inset


\begin_inset Separator latexpar
\end_inset


\end_layout

\begin_deeper
\begin_layout Pause

\end_layout

\end_deeper
\begin_layout Itemize
The vector 
\begin_inset Formula $\left(\gamma_{i}^{1},\ldots,\gamma_{i}^{k}\right)$
\end_inset

 is exactly the 
\series bold
soft assignment
\series default
 for 
\begin_inset Formula $x_{i}$
\end_inset

.
\begin_inset Separator latexpar
\end_inset


\end_layout

\begin_deeper
\begin_layout Pause

\end_layout

\end_deeper
\begin_layout Itemize
Let 
\begin_inset Formula $n_{c}=\sum_{i=1}^{n}\gamma_{i}^{c}$
\end_inset

 be the number of points 
\begin_inset Quotes eld
\end_inset

soft assigned
\begin_inset Quotes erd
\end_inset

 to cluster 
\begin_inset Formula $c$
\end_inset

.
\end_layout

\end_deeper
\begin_layout Standard
\begin_inset Separator parbreak
\end_inset


\end_layout

\begin_layout Frame
\begin_inset Argument 4
status open

\begin_layout Plain Layout
EM Algorithm for GMM: Overview
\end_layout

\end_inset


\end_layout

\begin_layout Frame
\begin_inset Separator latexpar
\end_inset


\end_layout

\begin_deeper
\begin_layout Enumerate
Initialize parameters 
\begin_inset Formula $\mu,\Sigma,\pi$
\end_inset

.
\begin_inset Separator latexpar
\end_inset


\end_layout

\begin_deeper
\begin_layout Pause

\end_layout

\end_deeper
\begin_layout Enumerate
\begin_inset Quotes eld
\end_inset

E step
\begin_inset Quotes erd
\end_inset

.
 Evaluate the responsibilities using current parameters:
\begin_inset Formula 
\[
\gamma_{i}^{j}=\frac{\pi_{j}\cn\left(x_{i}\mid\mu_{j},\Sigma_{j}\right)}{\sum_{c=1}^{k}\pi_{c}\cn\left(x_{i}\mid\mu_{c},\Sigma_{c}\right)},
\]

\end_inset

for 
\begin_inset Formula $i=1,\ldots,n$
\end_inset

 and 
\begin_inset Formula $j=1,\ldots,k$
\end_inset

.
\begin_inset Separator latexpar
\end_inset


\end_layout

\begin_deeper
\begin_layout Pause

\end_layout

\end_deeper
\begin_layout Enumerate
\begin_inset Quotes eld
\end_inset

M step
\begin_inset Quotes erd
\end_inset

.
 Re-estimate the parameters using responsibilities:
\begin_inset Formula 
\begin{eqnarray*}
\mu_{c}^{\text{new}} & = & \frac{1}{n_{c}}\sum_{i=1}^{n}\gamma_{i}^{c}x_{i}\\
\pause\Sigma_{c}^{\text{new}} & = & \frac{1}{n_{c}}\sum_{i=1}^{n}\gamma_{i}^{c}\left(x_{i}-\mu_{\text{MLE}}\right)\left(x_{i}-\mu_{\text{MLE}}\right)^{T}\\
\pause\pi_{c}^{\text{new}} & = & \frac{n_{c}}{n},
\end{eqnarray*}

\end_inset


\end_layout

\begin_layout Enumerate
Repeat from Step 2, until log-likelihood converges.
 
\end_layout

\end_deeper
\begin_layout Standard
\begin_inset Separator parbreak
\end_inset


\end_layout

\begin_layout Frame
\begin_inset Argument 4
status open

\begin_layout Plain Layout
EM for GMM
\end_layout

\end_inset


\end_layout

\begin_layout Frame
\begin_inset Separator latexpar
\end_inset


\end_layout

\begin_deeper
\begin_layout Itemize
Initialization
\end_layout

\begin_layout Standard
\align center
\begin_inset Graphics
	filename ../Figures/clustering/9.8a.png
	lyxscale 50
	height 55theight%

\end_inset


\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
let
\backslash
thefootnote
\backslash
relax
\backslash
footnotetext{
\backslash
tiny{From Bishop's 
\backslash
emph{Pattern recognition and machine learning}, Figure 9.8.}}
\end_layout

\end_inset


\end_layout

\end_deeper
\begin_layout Frame

\end_layout

\begin_layout Standard
\begin_inset Separator parbreak
\end_inset


\end_layout

\begin_layout Frame
\begin_inset Argument 4
status open

\begin_layout Plain Layout
EM for GMM
\end_layout

\end_inset


\end_layout

\begin_layout Frame
\begin_inset Separator latexpar
\end_inset


\end_layout

\begin_deeper
\begin_layout Itemize
First soft assignment:
\end_layout

\begin_layout Standard
\align center
\begin_inset Graphics
	filename ../Figures/clustering/9.8b.png
	lyxscale 50
	height 55theight%

\end_inset


\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
let
\backslash
thefootnote
\backslash
relax
\backslash
footnotetext{
\backslash
tiny{From Bishop's 
\backslash
emph{Pattern recognition and machine learning}, Figure 9.8.}}
\end_layout

\end_inset


\end_layout

\end_deeper
\begin_layout Frame

\end_layout

\begin_layout Standard
\begin_inset Separator parbreak
\end_inset


\end_layout

\begin_layout Frame
\begin_inset Argument 4
status open

\begin_layout Plain Layout
EM for GMM
\end_layout

\end_inset


\end_layout

\begin_layout Frame
\begin_inset Separator latexpar
\end_inset


\end_layout

\begin_deeper
\begin_layout Itemize
First soft assignment:
\end_layout

\begin_layout Standard
\align center
\begin_inset Graphics
	filename ../Figures/clustering/9.8c.png
	lyxscale 50
	height 55theight%

\end_inset


\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
let
\backslash
thefootnote
\backslash
relax
\backslash
footnotetext{
\backslash
tiny{From Bishop's 
\backslash
emph{Pattern recognition and machine learning}, Figure 9.8.}}
\end_layout

\end_inset


\end_layout

\end_deeper
\begin_layout Frame

\end_layout

\begin_layout Standard
\begin_inset Separator parbreak
\end_inset


\end_layout

\begin_layout Frame
\begin_inset Argument 4
status open

\begin_layout Plain Layout
EM for GMM
\end_layout

\end_inset


\end_layout

\begin_layout Frame
\begin_inset Separator latexpar
\end_inset


\end_layout

\begin_deeper
\begin_layout Itemize
After 5 rounds of EM:
\end_layout

\begin_layout Standard
\align center
\begin_inset Graphics
	filename ../Figures/clustering/9.8e.png
	lyxscale 50
	height 55theight%

\end_inset


\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
let
\backslash
thefootnote
\backslash
relax
\backslash
footnotetext{
\backslash
tiny{From Bishop's 
\backslash
emph{Pattern recognition and machine learning}, Figure 9.8.}}
\end_layout

\end_inset


\end_layout

\end_deeper
\begin_layout Frame

\end_layout

\begin_layout Standard
\begin_inset Separator parbreak
\end_inset


\end_layout

\begin_layout Frame
\begin_inset Argument 4
status open

\begin_layout Plain Layout
EM for GMM
\end_layout

\end_inset


\end_layout

\begin_layout Frame
\begin_inset Separator latexpar
\end_inset


\end_layout

\begin_deeper
\begin_layout Itemize
After 20 rounds of EM:
\end_layout

\begin_layout Standard
\align center
\begin_inset Graphics
	filename ../Figures/clustering/9.8f.png
	lyxscale 50
	height 55theight%

\end_inset


\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
let
\backslash
thefootnote
\backslash
relax
\backslash
footnotetext{
\backslash
tiny{From Bishop's 
\backslash
emph{Pattern recognition and machine learning}, Figure 9.8.}}
\end_layout

\end_inset


\end_layout

\end_deeper
\begin_layout Frame

\end_layout

\begin_layout Standard
\begin_inset Separator parbreak
\end_inset


\end_layout

\begin_layout Frame
\begin_inset Argument 4
status open

\begin_layout Plain Layout
Relation to 
\begin_inset Formula $K$
\end_inset

-Means
\end_layout

\end_inset


\end_layout

\begin_layout Frame
\begin_inset Separator latexpar
\end_inset


\end_layout

\begin_deeper
\begin_layout Itemize
EM for GMM seems a little like 
\begin_inset Formula $k$
\end_inset

-means.
\begin_inset Separator latexpar
\end_inset


\end_layout

\begin_deeper
\begin_layout Pause

\end_layout

\end_deeper
\begin_layout Itemize
In fact, there is a precise correspondence.
\begin_inset Separator latexpar
\end_inset


\end_layout

\begin_deeper
\begin_layout Pause

\end_layout

\end_deeper
\begin_layout Itemize
First, fix each cluster covariance matrix to be 
\begin_inset Formula $\sigma^{2}I$
\end_inset

.
 
\begin_inset Separator latexpar
\end_inset


\end_layout

\begin_deeper
\begin_layout Pause

\end_layout

\end_deeper
\begin_layout Itemize
As we take 
\begin_inset Formula $\sigma^{2}\to0$
\end_inset

, the update equations converge to doing 
\begin_inset Formula $k$
\end_inset

-means.
\begin_inset Separator latexpar
\end_inset


\end_layout

\begin_deeper
\begin_layout Pause

\end_layout

\end_deeper
\begin_layout Itemize
If you do a quick experiment yourself, you'll find
\begin_inset Separator latexpar
\end_inset


\end_layout

\begin_deeper
\begin_layout Itemize
Soft assignments converge to hard assignments.
\end_layout

\begin_layout Itemize
Has to do with the tail behavior (exponential decay) of Gaussian.
\end_layout

\end_deeper
\end_deeper
\begin_layout Standard
\begin_inset Separator parbreak
\end_inset


\end_layout

\end_body
\end_document
