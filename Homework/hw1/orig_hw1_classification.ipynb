{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML 101: HW #1\n",
    "\n",
    "<h4>Data Set Details:</h4>\n",
    "<b>\n",
    "* Predict whether income exceeds $50K/yr based on census data.\n",
    "* Binary Classification Problem\n",
    "* https://archive.ics.uci.edu/ml/datasets/Adult\n",
    "</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "from numpy import random as rnd\n",
    "\n",
    "rnd.seed (99)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading and preprocessing data\n",
    "\n",
    "#### 1. Load the data from census_data_train_clean.csv\n",
    "<i> Hint: use read_csv() </i>\n",
    "#### 2. Explore the data\n",
    "<i>Hint: useful functions include read_csv(), head() and describe()</i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education-num</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>5</td>\n",
       "      <td>77516</td>\n",
       "      <td>13</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2174</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>4</td>\n",
       "      <td>83311</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38</td>\n",
       "      <td>2</td>\n",
       "      <td>215646</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53</td>\n",
       "      <td>2</td>\n",
       "      <td>234721</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28</td>\n",
       "      <td>2</td>\n",
       "      <td>338409</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  workclass  fnlwgt  education-num  marital-status  occupation  race  \\\n",
       "0   39          5   77516             13               4           0     4   \n",
       "1   50          4   83311             13               2           3     4   \n",
       "2   38          2  215646              9               0           5     4   \n",
       "3   53          2  234721              7               2           5     2   \n",
       "4   28          2  338409             13               2           9     2   \n",
       "\n",
       "   sex  capital-gain  capital-loss  hours-per-week  income  \n",
       "0    1          2174             0              40       0  \n",
       "1    1             0             0              13       0  \n",
       "2    1             0             0              40       0  \n",
       "3    1             0             0              40       0  \n",
       "4    0             0             0              40       0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#path = 'datasets/assignment1/'\n",
    "#file = 'adult_data_1.csv'\n",
    "path = ''\n",
    "file = 'census_data_train_clean.csv'\n",
    "census_data = pd.read_csv (path+file, sep='\\s*,\\s*', engine='python')\n",
    "census_data.head (5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education-num</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>30718.000000</td>\n",
       "      <td>30718.000000</td>\n",
       "      <td>3.071800e+04</td>\n",
       "      <td>30718.000000</td>\n",
       "      <td>30718.000000</td>\n",
       "      <td>30718.000000</td>\n",
       "      <td>30718.000000</td>\n",
       "      <td>30718.000000</td>\n",
       "      <td>30718.000000</td>\n",
       "      <td>30718.000000</td>\n",
       "      <td>30718.000000</td>\n",
       "      <td>30718.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>38.443584</td>\n",
       "      <td>2.199720</td>\n",
       "      <td>1.898455e+05</td>\n",
       "      <td>10.130314</td>\n",
       "      <td>2.583143</td>\n",
       "      <td>5.967088</td>\n",
       "      <td>3.670161</td>\n",
       "      <td>0.676737</td>\n",
       "      <td>1106.037079</td>\n",
       "      <td>88.910216</td>\n",
       "      <td>40.949313</td>\n",
       "      <td>0.249040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>13.118227</td>\n",
       "      <td>0.952936</td>\n",
       "      <td>1.054583e+05</td>\n",
       "      <td>2.562469</td>\n",
       "      <td>1.495674</td>\n",
       "      <td>4.025999</td>\n",
       "      <td>0.844063</td>\n",
       "      <td>0.467730</td>\n",
       "      <td>7497.863364</td>\n",
       "      <td>405.657203</td>\n",
       "      <td>11.985382</td>\n",
       "      <td>0.432464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>17.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.376900e+04</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>28.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.178285e+05</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>37.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.785170e+05</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>47.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.373170e+05</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>90.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>1.484705e+06</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>99999.000000</td>\n",
       "      <td>4356.000000</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                age     workclass        fnlwgt  education-num  \\\n",
       "count  30718.000000  30718.000000  3.071800e+04   30718.000000   \n",
       "mean      38.443584      2.199720  1.898455e+05      10.130314   \n",
       "std       13.118227      0.952936  1.054583e+05       2.562469   \n",
       "min       17.000000      0.000000  1.376900e+04       1.000000   \n",
       "25%       28.000000      2.000000  1.178285e+05       9.000000   \n",
       "50%       37.000000      2.000000  1.785170e+05      10.000000   \n",
       "75%       47.000000      2.000000  2.373170e+05      13.000000   \n",
       "max       90.000000      6.000000  1.484705e+06      16.000000   \n",
       "\n",
       "       marital-status    occupation          race           sex  capital-gain  \\\n",
       "count    30718.000000  30718.000000  30718.000000  30718.000000  30718.000000   \n",
       "mean         2.583143      5.967088      3.670161      0.676737   1106.037079   \n",
       "std          1.495674      4.025999      0.844063      0.467730   7497.863364   \n",
       "min          0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%          2.000000      2.000000      4.000000      0.000000      0.000000   \n",
       "50%          2.000000      6.000000      4.000000      1.000000      0.000000   \n",
       "75%          4.000000      9.000000      4.000000      1.000000      0.000000   \n",
       "max          6.000000     13.000000      4.000000      1.000000  99999.000000   \n",
       "\n",
       "       capital-loss  hours-per-week        income  \n",
       "count  30718.000000    30718.000000  30718.000000  \n",
       "mean      88.910216       40.949313      0.249040  \n",
       "std      405.657203       11.985382      0.432464  \n",
       "min        0.000000        1.000000      0.000000  \n",
       "25%        0.000000       40.000000      0.000000  \n",
       "50%        0.000000       40.000000      0.000000  \n",
       "75%        0.000000       45.000000      0.000000  \n",
       "max     4356.000000       99.000000      1.000000  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sn: graphically explore the relationships of festures with the label\n",
    "census_data.describe ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['age', 'workclass', 'fnlwgt', 'education-num', 'marital-status',\n",
       "       'occupation', 'race', 'sex', 'capital-gain', 'capital-loss',\n",
       "       'hours-per-week', 'income'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "census_data.keys ()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Preprocessing Data: Identify the categorical columns and create new columns with their one-hot encoding\n",
    "<i> Hint: sklearn has a OneHotEncoder class </i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-41-8487cf79ea68>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m                    \"State-gov\", \"Without-pay\", \"Never-worked\"]\n\u001b[1;32m      3\u001b[0m \u001b[0mset_workclass_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlist_workclass_values\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mcensus_data_clean\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcensus_data\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnotnull\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mcensus_data\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"workclass\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mcensus_data\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"workclass\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mset_workclass_values\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mcensus_data_clean\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdescribe\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__nonzero__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    953\u001b[0m         raise ValueError(\"The truth value of a {0} is ambiguous. \"\n\u001b[1;32m    954\u001b[0m                          \u001b[0;34m\"Use a.empty, a.bool(), a.item(), a.any() or a.all().\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 955\u001b[0;31m                          .format(self.__class__.__name__))\n\u001b[0m\u001b[1;32m    956\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    957\u001b[0m     \u001b[0m__bool__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m__nonzero__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all()."
     ]
    }
   ],
   "source": [
    "list_workclass_values = [\"Private\", \"Self-emp-not-inc\", \"Self-emp-inc\", \"Federal-gov\", \"Local-gov\", \n",
    "                   \"State-gov\", \"Without-pay\", \"Never-worked\"]\n",
    "set_workclass_values = set (list_workclass_values)\n",
    "census_data_clean = census_data [pd.notnull (census_data [\"workclass\"]) and census_data [\"workclass\"] in set_workclass_values]\n",
    "census_data_clean.describe ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "y contains new labels: ['?']",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-39-9fa4556a7969>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0menc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreprocessing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOneHotEncoder\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mcensus_data_clean\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"workclass_code\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mworkClassEnc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mcensus_data_clean\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'workclass'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;31m#census_data [\"education_code\"] = educationEnc.fit_transform (census_data ['education'])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m#census_data [\"workclass_1h_code\"] = enc.fit (census_data [\"workclass_code\"].reshape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/sklearn/preprocessing/label.py\u001b[0m in \u001b[0;36mtransform\u001b[0;34m(self, y)\u001b[0m\n\u001b[1;32m    131\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintersect1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclasses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclasses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m             \u001b[0mdiff\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetdiff1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclasses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 133\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"y contains new labels: %s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdiff\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    134\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msearchsorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: y contains new labels: ['?']"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "workClassEnc = LabelEncoder ()\n",
    "workClassEnc.fit ([\"Private\", \"Self-emp-not-inc\", \"Self-emp-inc\", \"Federal-gov\", \"Local-gov\", \n",
    "                   \"State-gov\", \"Without-pay\", \"Never-worked\"])\n",
    "educationEnc = LabelEncoder ()\n",
    "enc = preprocessing.OneHotEncoder ()\n",
    "\n",
    "census_data_clean [\"workclass_code\"] = workClassEnc.transform (census_data_clean ['workclass'])\n",
    "#census_data [\"education_code\"] = educationEnc.fit_transform (census_data ['education'])\n",
    "#census_data [\"workclass_1h_code\"] = enc.fit (census_data [\"workclass_code\"].reshape)\n",
    "#cat_features = enc.fit (census_data [\"workclass_code\"].values.reshape (-1,1))\n",
    "#workclass_feature.head (10)\n",
    "#census_data [\"workclass_1h_code\"]\n",
    "census_data_clean [[\"workclass\", \"workclass_code\"]].head (10)\n",
    "#census_data [\"education-num\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. Split data into training, validation, test sets of the sizes: train_size=500, valid_size=5000, test_size=5000\n",
    "<i> Hint: sklearn has a train_test_split function</i>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6. Baseline Error Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Income &gt;= 50K</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Income >= 50K\n",
       "0           0.75\n",
       "1           0.25"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pct_values = pd.Series(y_train).value_counts() / train_size\n",
    "no_info_rate = pct_values.min()\n",
    "## the data frame conversion is for the values to displayed nicely.\n",
    "pd.DataFrame(pct_values, columns=['Income >= 50K'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* <h5>In case of no other information, best predictor will be to always predict 0!</h5>\n",
    "* <h5>For this data, we will be correct 75% of the time!</h5>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7. Normalization of Features: to save time, we have completed this step for you"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Need to normalize features for some models\n",
    "scaler = StandardScaler()\n",
    "## normalizing the training data. Centering and scaling.\n",
    "X_train_norm = scaler.fit_transform(X_train)\n",
    "\n",
    "## applying the same normalization to validation and test data\n",
    "X_valid_norm = scaler.transform(X_valid)\n",
    "X_test_norm = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitting a Simple Model - Logistic Regression\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Usesklearn's LogisticRegression class to train a model. Print out the error rate for the training and validation sets\n",
    "<i> Hint: use score() function to get error rate</i>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Explore the Effect of Regularization of Logistic Regression\n",
    "\n",
    "a. L1 regularization: Vary the C term (the regularization parameter) and create a table showing the model coefficients generated by each C term. For what C term, is the validation error rate at a minimum?\n",
    "\n",
    "b. L2 regularization: Vary the C term (the regularization parameter) and create a table showing the model coefficients generated by each C term. For what C term, is the validation error rate at a minimum?\n",
    "\n",
    "c. What differences do you notice between the models generated using L1 regularization vs L2 regularization?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Use this range of regularization parameterse\n",
    "Cs = np.array([1e-5, 0.0001, 0.001, 0.01, 0.1, 1.0, 10.0, 100.0, 1000.0, 10000.0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A Different Model: Random Forest Classifier\n",
    "#### 1. Use the RandomForestClassifer to train a model. Print out the error rate for the training and validation sets. Play around with changing the different parameters (eg. max_depth) to see what impact it has on the error rate. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Effect of Training Data size on the error rates\n",
    "\n",
    "#### 1. Vary the size of the training data and then train a Logistic Regression Model. What effect does training size have on error rates?\n",
    "#### 2. Vary the size of the training data and then train a Random Model. What effect does training size have on error rates?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a3016bc1cb546228e5ff782c7779e13"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## proportion of the training data to use\n",
    "train_proportions = np.array([0.001, 0.005, 0.01, 0.025, 0.05, 0.075, 0.1, 0.25, 0.5, 0.75])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {
    "5d0f6ee8fa5643fb9e6efd210673d768": {
     "views": [
      {
       "cell_index": 35
      }
     ]
    },
    "6a3f05968c40448b9e9328b923b4148b": {
     "views": [
      {
       "cell_index": 32
      }
     ]
    },
    "a260635cc8464e51b80603e61c086bd8": {
     "views": [
      {
       "cell_index": 37
      }
     ]
    },
    "b043e76a9f4c482a8075f8a32fa42c0a": {
     "views": [
      {
       "cell_index": 19
      }
     ]
    },
    "b5aff08a845d47e6b2129f027bcae5fe": {
     "views": [
      {
       "cell_index": 24
      }
     ]
    },
    "d97c351461e44a60b6153603580fab58": {
     "views": [
      {
       "cell_index": 32
      }
     ]
    }
   },
   "version": "1.2.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
